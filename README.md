# Vid2Txt
Video to text recognition
Демонстрационные данные доступны по следующим ссылкам:
- https://disk.yandex.ru/i/8Vwbi_3PbFUlMA - (Видеофайл с речью средней скорости)
- https://disk.yandex.ru/i/P3_OP9cPLYILHQ - (Видеофайл с быстрой речью)

Данный проект включает в себя два способа получения текста из видео.

Первый файл "Vid2Txt/VTT/VTT.py" основан на модели библиотеки "Vosk" доступной по ссылке: https://alphacephei.com/vosk/models/vosk-model-ru-0.10.zip
Модель должна быть распакована в папку с файлом (локально), для этого можно использовать скрипт, расположенный тут - "Vid2Txt/VTT/unzipper.py".
Файл для обработки должен быть загружен в папку с моделью в формате ".mp4" и в файле "VTT.py" должен быть изменён путь (13 строка).
Далее происходит разделение целого видеофайла на видео и аудио дорожки, где аудиодорожка сохраняется отдельно.
После выполнения алгоритма результат работы будет представлен в виде файла "result.txt", который запишется в папке с моделью.

Второй файл "Vid2Txt/VTT_split/VTT_wsplit.py" основан на google speech_recognition модели, которая выводит ответ по частям, записывая конечный результат в один файл с расширением ".txt".
Для работы алгоритма необходимо подключение к Сети.
Также необходимо указать директорию файла (10 строка) не указывая названия самого файла.
Название самого файла (без его расширения) необходимо указать в строке 13.
Далее, в процессе работы алгоритма, будет отдельно создан и сохранён аудио файл, из которого будет распознаваться текст.
Результат работы программы можно будет увидеть в файле с названием, которое будет сформировано следующим образом - изначальное название файла + transcription.txt.
Данный файл можно будет найти в той же папке, где расположен файл с выполняемым алгоритмом.

Необходимые для работы библиотеки могут быть установлены при помощи файла "requirements.txt".
